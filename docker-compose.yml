version: "3.9"

# This docker compose uses profiles - see https://docs.docker.com/compose/profiles/

# 
# DOCKER IMAGES
#

# 13-3.1 is the first pg version with FORCE_SSL support
# needed to force clients to use SSL
x-postgres-image: &postgres-image kartoza/postgis:13-3.1
x-osm-update-image: &osm-update-image kartoza/docker-osm:osmupdate-latest
x-imposm-image: &imposm-image kartoza/docker-osm:imposm-latest
x-osmenrich-image: &osm-enrich-image kartoza/docker-osm:osmenrich-latest
# Special build of the kartoza geoserver image which includes the 
# plugins etc. GeoNode needs to communicate with GeoServer
x-geoserver-image: &geoserver-image kartoza/geoserver:2.18.2
x-mergin-db-sync-image: &mergin-db-sync-image lutraconsulting/mergin-db-sync
# alpine spin needed for bcrypt support
x-nginx-image: &nginx-image nginx:alpine
x-certbot-image: &certbot-image certbot/certbot
x-qgis-server-image: &qgis-server-image openquake/qgis-server:stable
x-qgis-desktop-image: &qgis-desktop-image tswetnam/xpra-qgis:bionic
x-mapproxy-image: &mapproxy-image kartoza/mapproxy
x-postgrest-image: &postgrest-image postgrest/postgrest
x-swagger-image: &swagger-image swaggerapi/swagger-ui
x-scp-image: &scp-image quay.io/lkiesow/docker-scp
x-odm-image: &odm-image opendronemap/odm
x-gdal-image: &gdal-image geodata/gdal
x-mergin-client-image: &mergin-client-image kartoza/mergin-client:latest
x-lizmap-image: &lizmap-image 3liz/lizmap-web-client:3.4
# Auto builds on the main branch are tagged with :main
x-hugo-image: &hugo-image kartoza/hugo-watcher:main
x-node-red-image: &node-red-image nodered/node-red:latest

# 
# VOLUMES
#

# Generally we are using docker volumes for all volumes
# except conf files which are host mounted volumes out
# of our git repo.
# 

volumes:
  import_done:
  import_queue:
  postgis_data:
  geoserver_data:
  mapproxy_data:
  mergin_sync_data:
  osm_import_done:
  osm_import_queue:
  osm_cache:
  odm_cutline:
  odm_datasets:
  mergin-projects:
  # used by lizmap and mergin web server and perhaps others
  redis_data:
  cache:
  generated_hugo_data:
  #
  # For uploading stuff via scp
  #
  scp_etc:
  # Mounted in SCP and to geoserver for a file store
  scp_geoserver_data:
  # Mounted in SCP and to QGIS Server for serving QGIS projects
  qgis_projects:
  # Mounted in SCP and to QGIS Server for serving QGIS fonts
  scp_qgis_fonts:
  # Mounted in SCP and to QGIS Server for serving QGIS svgs
  scp_qgis_svg:
  # Mounted in SCP and to Hugo for static content (js/css/img)
  scp_hugo_static:
  # Mounted in SCP and to Hugo for content (markdown)
  scp_hugo_data:
  # Mounted in SCP and to ODM for processing uploaded images
  scp_odm_data:
  # Mounted in SCP only for data sharing
  scp_general_data:
  # Lizmap related volumes
  lizmap-theme-config:
  lizmap-config:
  lizmap-db:
  lizmap-www:
  lizmap-log:
  # For node red
  node-red-data:

#
# SERVICES
#

services:
 
  ############################################################
  #
  # First we define all default services that are run if
  # you do not specify a profile. These are currently
  # nginx, hugo watcher and scp.
  #
  ############################################################
 
  # Nginx with ssl      
  nginx:
    image: *nginx-image
    volumes:
     - ./conf/nginx_conf/nginx.conf:/etc/nginx/nginx.conf
     # You must manually create this file before running
     # by running either
     # make configure-ssl-self-signed
     # or
     # make configure-letsencrypt-ssl
     - ./conf/nginx_conf/servername.conf:/etc/nginx/servername.conf
     - ./conf/nginx_conf/upstreams:/etc/nginx/upstreams
     - ./conf/nginx_conf/ssl:/etc/nginx/ssl
     - ./conf/nginx_conf/locations:/etc/nginx/locations
     - ./conf/nginx_conf/htpasswd:/etc/nginx/.htpasswd
     # If you are running with a self signed certificate
     # then make sure the following folder contains these files 
     # nginx-selfsigned.crt
     # nginx-selfsigned.key
     # You can generate them (or a proper letsencrypt cert)
     # by running either
     # make configure-ssl-self-signed
     # or
     # make configure-letsencrypt-ssl
     - ./certbot/certbot/conf:/etc/letsencrypt
     - ./certbot/certbot/www:/var/www/certbot
     # Mount the mergin db sync data into nginx so we can access
     # images etc.
     # Ideally we should only be mounting the image subfolders to
     # avoid leaking our geopackage etc.
     # To do that the mergin project needs to be set up accordingly
     # - TODO for the future
     - mergin_sync_data:/mergin-data
     # mount the hugo data folder so that we can serve the static site
     - generated_hugo_data:/hugo
     # General sharing of files to the web
     - scp_general_data:/files
     # mount the docs folder as /docs and make it available
     # at /docs in the web site
     # Run make docs to generate latest help
     # You also need to do make enable-docs for the docs to show on your site
     - ./docs:/docs
    # This makes nginx reload its configuration (and certificates)
    # every six hours in the background and launches nginx in the
    # foreground.
    # See
    # https://medium.com/@pentacent/nginx-and-lets-encrypt-with-docker-in-less-than-5-minutes-b4b8a60d3a71
    command: "/bin/sh -c 'while :; do sleep 6h & wait $${!}; nginx -s reload; done & nginx -g \"daemon off;\"'"
    # For debugging config issues
    #command: "sleep 3000"
    ports:
     - "80:80"
     - "443:443"
    networks:
     - os-gis-stack
    restart: unless-stopped
    logging:
      driver: json-file
      options:
        max-size: 200m
        max-file: '10'
    depends_on:
      - scp
      - hugo-watcher

  certbot:
    image: *certbot-image
    profiles: ["all","certbot-init"]
    # This checks every 12 hours if our cert is up for renewal and
    # refreshes it if needed
    # See https://medium.com/@pentacent/nginx-and-lets-encrypt-with-docker-in-less-than-5-minutes-b4b8a60d3a71
    entrypoint: "/bin/sh -c 'trap exit TERM; while :; do certbot renew; sleep 12h & wait $${!}; done;'"
    depends_on:
      - nginx
    volumes:
     - ./certbot/certbot/conf:/etc/letsencrypt
     - ./certbot/certbot/www:/var/www/certbot


  # This is only intended to be used during the initial setup of
  # certbot, thereafter use the nginx service
  # See the makefile for how this is orchestrated       
  nginx-certbot-init:
    image: *nginx-image
    profiles:
        - certbot-init
    ports:
      - "80:80"
      - "443:443"
    volumes:
     - ./nginx_certbot_init_conf/nginx.conf:/etc/nginx/nginx.conf
     - ./certbot/certbot/conf:/etc/letsencrypt
     - ./certbot/certbot/www:/var/www/certbot

  hugo-watcher:
    # This service watches for changes in the static content
    # source files of the hugo site and rebuilds the site 
    # whenver a source file is changed.
    # Use the scp service to upload your markdown files to
    # scp_hugo_data.
    image: *hugo-image
    # No profiles specified, automatically started by nginx
    volumes:
      # This is not user editable, generated static html
      # will be placed here.
      - generated_hugo_data:/src/public
      # Mounted in SCP and to Hugo for static content (js/css/img)
      # If empty, the folder will be pre-populated with the hugo docker
      # image's static_template folder
      # If empty, the folder will be pre-populated with the hugo docker
      # image's static_template folder
      - scp_hugo_static:/src/static
      # Only raw markdown should be put in here
      - scp_hugo_data:/src/content
      # config from host mounted volume
      - ./conf/hugo_conf/config.yaml:/src/config.yaml

  ############################################################
  #  END OF DEFAULT SERVICES - everything after this
  #  needs to be explicitly started by passing a docker-compose
  #  profile as parameter.
  ############################################################

  db:
    image: *postgres-image
    profiles:
        - db
        - postgres
        - osm
        - qgis-server
        - qgis-desktop
        - mergin
        - mergin-server
        - dev
    volumes:
      # Persistent storage of the database cluster 
      - postgis_data:/var/lib/postgresql
      # So we can use SSL certs for pg too
      # Currently NOT WORKING - eventually we can set this and then
      # Enable full CA based encryption
      - ./certbot/certbot/conf:/etc/letsencrypt
    env_file: .env
    environment:
      # You can define multiple databases by providing a comma
      # separated list here.
      # gis - for general purpose gis projects
      # mergin-server - for mergin server flask app
      # mergin - for mergin-db-sync
      - POSTGRES_DB=gis,mergin-server,mergin
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASS=${POSTGRES_PASSWORD}
      # Read the notes at
      # https://github.com/kartoza/docker-postgis#postgres-ssl-setup
      # Certificate from letsencrypt doesn't currently work
      #- SSL_CERT_FILE=/etc/letsencrypt/live/${DOMAIN}/cert.pems
      #- SSL_KEY_FILE=/etc/letsencrypt/live/${DOMAIN}/privkey.pem
      #- SSL_CA_FILE=/your/own/ssl_ca_file.pem
      # Force clients to connect with SSL - will add hostssl
      # instead of host to lines in pg_hba.conf
      - FORCE_SSL=TRUE
      # When connecting using your client, set SSL mode to 'Require'
      # If you want force using a certificate, use PASSWORD_AUTHENTICATION=cert
      # But then you also need to deploy certificates (again see the docs above)
      - ALLOW_IP_RANGE=0.0.0.0/0
      - PASSWORD_AUTHENTICATION=scram-sha-256
      # You can pass as many extensions as you need.
      - POSTGRES_MULTIPLE_EXTENSIONS=postgis,hstore,postgis_topology,postgis_raster,pgrouting
      # Some extensions need to be registered in the postgresql.conf as
      # shared_preload_libraries. pg_cron should always be added because the
      # extension is installed with the image.
      - SHARED_PRELOAD_LIBRARIES=pg_cron 
      - DEFAULT_ENCODING="UTF8"
      - DEFAULT_COLLATION="en_US.UTF-8"
      - DEFAULT_CTYPE="en_US.UTF-8"
      - POSTGRES_TEMPLATE_EXTENSIONS=true

    networks:
     - os-gis-stack
    ports:
      - ${POSTGRES_PUBLIC_PORT}:${POSTGRES_PRIVATE_PORT} 
    restart: unless-stopped
    healthcheck:
        test: "exit 0"

  lizmap:
    # This is not WORKING YET!
    # Need to resolve an issue with lizmap home still......
    image: *lizmap-image
    profiles:
        - lizmap
    command: 
      - php-fpm
    env_file: .env
    environment:
      LIZMAP_WPS_URL: https://${DOMAIN}/lizmap/ # see nginx.conf
      LIZMAP_CACHESTORAGETYPE: redis   
      LIZMAP_CACHEREDISDB: '1'
      LIZMAP_USER: '1010'
      LIZMAP_WMSSERVERURL: https://${DOMAIN}/lizmap/ows/
      LIZMAP_CACHEREDISHOST: redis
      LIZMAP_HOME: /srv/lizmap/
    volumes:
      - qgis_projects:/srv/projects
      - lizmap-theme-config:/www/lizmap/var/lizmap-theme-config
      - lizmap-config:/www/lizmap/var/config
      - lizmap-db:/www/lizmap/var/db
      - lizmap-www:/www/lizmap/www
      - lizmap-log:/www/lizmap/var/log
      - ./lizmap:/srv/lizmap
    networks:
      - os-gis-stack

  # used by lizmap and mergin web server and perhaps others
  redis:
    image: redis:5-alpine
    profiles:
      - lizmap    
      - mergin-server
    volumes:
      - redis_data:/data
    ports:
      - 6379   
    networks:
      - os-gis-stack  

  # Geoserver backend specifically supporting GeoNode
  # that includes the GeoNode plugins
  # deployed in the Kartoza GeoServer image
  geoserver:
    image: *geoserver-image
    profiles: 
        - geoserver
    healthcheck:
      test: "curl --fail --silent --write-out 'HTTP CODE : %{http_code}\n' --output /dev/null http://127.0.0.1:8080/geoserver"
      interval: 60s
      timeout: 10s
      retries: 1 
      start_period: 60s
    depends_on:
        - nginx
        - scp
    env_file:
      # Editable configs (will be edited by make configure or by user)
      - .env
    environment:
      - ADMIN_USERNAME=${GEOSERVER_ADMIN_USER}
      - ADMIN_PASSWORD=${GEOSERVER_ADMIN_PASSWORD}
      - INITIAL_MEMORY=${INITIAL_MEMORY}
      - MAXIMUM_MEMORY=${MAXIMUM_MEMORY}
      - STABLE_EXTENSIONS=importer-plugin
      - HTTPS_HOST=${DOMAIN}
      - HTTPS_PORT=443
      - HTTP_HOST=127.0.0.1
      - HTTP_PORT=80
      - GEOSERVER_DATA_DIR=/opt/geoserver/data_dir
    volumes:
      # This path is specified by the GEOSERVER_DATA_DIR
      - geoserver_data:/opt/geoserver/data_dir
      # Mounted in SCP and to geoserver for serving geoserver data
      # store
      - scp_geoserver_data:/data/scp_geoserver_data
    restart: on-failure
    networks:
      - os-gis-stack    

  qgis-server:
    image: *qgis-server-image
    profiles: 
      -  qgis-server 
    env_file: .env
    environment:
      # Do not run the embedded copy of nginx
      SKIP_NGINX: "true"
      # Improve rendering performance
      QGIS_SERVER_PARALLEL_RENDERING: "true"
      QGIS_SERVER_MAX_THREADS: 4
      # Limit the maximum size returned by a GetMap
      QGIS_SERVER_WMS_MAX_HEIGHT: 5000
      QGIS_SERVER_WMS_MAX_WIDTH: 5000
      # Verbose logging
      QGIS_SERVER_LOG_LEVEL: 0
      # Initialize the authentication system
      # creates or uses qgis-auth.db in ~/.qgis3/ or directory
      # defined by QGIS_AUTH_DB_DIR_PATH env variable
      # set the master password as first line of file defined by
      # QGIS_AUTH_PASSWORD_FILE env variable
      # (QGIS_AUTH_PASSWORD_FILE variable removed from environment
      # after accessing)
      # See also volume mounts below
      QGIS_AUTH_DB_DIR_PATH: /tmp/
      QGIS_AUTH_PASSWORD_FILE: /tmp/qgis-auth-pwd.txt
      # For OGC API
      # # Landing page plugin projects directory
      #QGIS_SERVER_LANDING_PAGE_PROJECTS_DIRECTORIES ${QGIS_SERVER_LANDING_PAGE_PROJECTS_DIRECTORIES}
      #QGIS_SERVER_LANDING_PAGE_PROJECTS_PG_CONNECTIONS postgresql://${POSTGRES_USER}:${POSTGRES_PASS}@postgis:5432?sslmode=disable&dbname=${POSTGRES_DBNAME}&schema=public`
    ports:
      - "9993"
    networks:
     - os-gis-stack
    volumes:
     # Data should be mount RO when working
     # with GeoPackages and more than one QGIS container
     # Data dir structure
     # $(pwd)/qgis_projects must have the following structure:
     #
     # data
     # |
     # |-- <project_name>
     #   |-- <project_name>.qgs
     # 
     # The data dir is mounted in the SCP volume
     # too so that you can upload your projects easily
     # using SCP and then have them published
     #
     - qgis_projects:/io/data:ro
     # 
     # qgis_plugins
     # |
     # |-- <plugin_name>
     #   |-- <plugin_code>.py
     #   |-- metadata.txt
     #   |-- __init__.py
     - ./qgis_plugins:/io/plugins
     #  
     # Custom fonts are loaded into /usr/share/fonts. fc-cache is
     # run when container is started.
     - scp_qgis_fonts:/usr/share/fonts
     - scp_qgis_svg:/var/lib/qgis/.local/share/QGIS/QGIS3/profiles/default/svg
     - ./conf/qgis_conf/qgis-auth.db:/tmp/qgis-auth.db
     - ./conf/qgis_conf/qgis-auth-pwd.txt:/tmp/qgis-auth-pwd.txt
     # Working path for the pg_service file if using
     # openquake/qgis-server:stable
     # See https://github.com/gem/oq-qgis-server/issues/54
     # The service file contains two service definitions
     # nginx - used for connecting to the database to load a QGIS
     #         project stored in the database
     #         In that case you cannot yet use qgis-auth.db
     #         database for user/pass credentials
     # smallholding - used for layer definitions. This service has
     #         no user/pass data and 
     #         instead we fetch those credentials from the qgis
     #         authdb
     - ./conf/pg_conf/pg_service.conf:/etc/postgresql-common/pg_service.conf:ro
     # As per the oq QGIS Server docs at
     # https://github.com/gem/oq-qgis-server/blob/master/README.md#postgresql-connection-service-file-optional
     # but wrong! 
     #This works instead for the openquake/qgis-server:3 image
     #- ./conf/pg_conf/pg_service.conf:/etc/pg_service.conf:ro

     # Mount the mergin db sync data into nginx so we can access
     # images etc.
     # Ideally we should only be mounting the image subfolders to
     # avoid leaking our geopackage etc.
     # To do that the mergin project needs to be set up accordingly
     # - TODO for the future
     - mergin_sync_data:/mergin-data     
    restart: unless-stopped
  
  # QGIS Desktop running in a web browser via XPRA
  # We will revers proxy it via nginx so no public port 
  # open here.
  qgis-desktop:
    image: *qgis-desktop-image
    profiles: 
      -  qgis-desktop
    networks:
     - os-gis-stack
    ports:
      - "9876"
    volumes:
     # qgis-projects
     # |
     # |-- <project_name>
     #   |-- <project_name>.qgs
     # 
     # The data dir is mounted in the SCP volume
     # too so that you can upload your projects easily
     # using SCP and then have them published
     #
     - qgis_projects:/qgis-projects
     # 
     # Custom fonts are loaded into /usr/share/fonts. fc-cache is
     # run when container is started.
     - scp_qgis_fonts:/usr/share/fonts
     # Need to check this
     - scp_qgis_svg:/var/lib/qgis/.local/share/QGIS/QGIS3/profiles/default/svg
     # and this
     - ./conf/qgis_conf/qgis-auth.db:/tmp/qgis-auth.db
     # Working path for the pg_service file
     - ./conf/pg_conf/pg_service.conf:/etc/postgresql-common/pg_service.conf:ro
     # Mount the mergin db sync data into nginx so we can access
     # images etc.
     # Ideally we should only be mounting the image subfolders to
     # avoid leaking our geopackage etc.
     # To do that the mergin project needs to be set up accordingly
     # - TODO for the future
     - mergin_sync_data:/mergin-data     
    restart: unless-stopped


  mapproxy:
    image: *mapproxy-image
    profiles: 
      - mapproxy
    env_file: .env
    environment:
      - PRODUCTION=false
      - PROCESSES=4
      - THREADS=10
    user: "1000:1000"
    volumes:
      - mapproxy_data:/mapproxy/
      - ./conf/mapproxy_conf/app.py:/mapproxy/app.py
      - ./conf/mapproxy_conf/seed.yaml:/mapproxy/seed.yaml
      - ./conf/mapproxy_conf/mapproxy.yaml:/mapproxy/mapproxy.yaml
      - ./conf/mapproxy_conf/clip:/mapproxy/clip
    networks:
     - os-gis-stack

  mapproxy-seed:
    ##
    ## Example usage: docker-compose --profile=mapproxy-seed up mapproxy-seed
    ## 
    ## Crank up the number of threads and processes if you have a 
    ## fast machine
    ##
    image: *mapproxy-image
    profiles: 
      - mapproxy-seed
    entrypoint: ["mapproxy-seed"]
    command: ["-c", "4", "-s", "/mapproxy/seed.yaml", "-f",  "/mapproxy/mapproxy.yaml"]
    env_file: .env
    environment:
      - PRODUCTION=True
      - PROCESSES=30
      - THREADS=100
    user: "1000:1000"
    volumes:
      - mapproxy_data:/mapproxy/
      - ./conf/mapproxy_conf/app.py:/mapproxy/app.py
      - ./conf/mapproxy_conf/seed.yaml:/mapproxy/seed.yaml
      - ./conf/mapproxy_conf/mapproxy.yaml:/mapproxy/mapproxy.yaml
      - ./conf/mapproxy_conf/clip:/mapproxy/clip
    networks:
      - os-gis-stack
    

  postgrest:
    #
    # Used for pushing readings from IoT devices to our database
    #
    image: *postgrest-image
    profiles: 
      - postgrest
      - db
    env_file: .env
    environment:
      PGRST_DB_URI: postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:${POSTGRES_PRIVATE_PORT}/gis
      PGRST_DB_SCHEMA: ${PGRST_DB_SCHEMA}
      # In production this role should not be the same as the one used for the connection
      # depends_on
      PGRST_DB_ANON_ROLE: ${PGRST_DB_ANON_ROLE}
      PGRST_SERVER_PROXY_URI: ${PGRST_SERVER_PROXY_URI}
      PGRST_OPENAPI_SERVER_PROXY_URI: ${PGRST_OPENAPI_SERVER_PROXY_URI}
      PGRST_SERVER_PORT: ${PGRST_SERVER_PORT}
    links:
      - db:db
    ports:
      - "3000"
    depends_on:
      - db
    networks:
      - os-gis-stack

  swagger:
    image: *swagger-image
    profiles: 
      - postgrest 
    ports:
      - "8080"
    volumes:
      - ./conf/swagger_conf/swagger.json:/swagger.json
    env_file: .env
    environment:
      SWAGGER_JSON: /swagger.json
      API_URL: ${API_URL}       
    depends_on:
      - db
      - postgrest
    networks:
      - os-gis-stack


#######################################################
#
# We provide an SCP server for copying content up to 
# the various services. View the readme for details.
#
#######################################################

  scp:
    image: *scp-image
    # No profiles specified, automatically started by nginx
    ports:
      # This is one of the few cases where we are 
      # exposing a port to the host. Users should
      # be able to use scp to upload qgis projects
      # data files for geoserver etc.
      - "2222:22"
    volumes:
      # Host mounted volumes./conf/mapproxy_conf/mapproxy.yml
      # We need to persist the /etc/ssh folder so that 
      # Docker restart don't create a new host key each time
      # because clients connecting will error out with host
      # key changed errors
      - scp_etc:/etc/ssh
      # One file per user, each file containing list
      # of ssh keys allowed to upload to the data dir
      # Files should be given same name as user
      - ./conf/scp_conf:/conf
      # Mounted in SCP and to geoserver for serving geoserver data
      # store
      - scp_geoserver_data:/data/geoserver_data
      # Mounted in SCP and to QGIS Server for serving QGIS projects
      - qgis_projects:/data/qgis_projects
      # Mounted in SCP and to QGIS Server for serving QGIS fonts
      - scp_qgis_fonts:/data/qgis_fonts
      # Mounted in SCP and to QGIS Server for serving QGIS svgs
      - scp_qgis_svg:/data/qgis_svg
      # Mounted in SCP and to Hugo for static content (js/css/img)
      - scp_hugo_static:/data/hugo_static
      # Mounted in SCP and to Hugo for rendering static pages
      - scp_hugo_data:/data/hugo_data
      # Mounted in SCP and to ODM for processing uploaded images
      - scp_odm_data:/data/odm_data
      # Mounted in SCP and under nginx as /files only for data sharing
      - scp_general_data:/data/general_data
    networks:
      - os-gis-stack  


  node-red:
    image: *node-red-image
    profiles: 
      - node-red
    env_file: .env
    environment:
      - TZ=${TIMEZONE}
    ports:
      - 1880
    networks:
      - os-gis-stack  
    volumes:
      - node-red-data:/data

  ############################################################
  #
  # MERGIN Service - this is not run in production by
  # default. It will sync your mergin projects to the db image.
  # To run do:
  #
  # docker-compose --profile=mergin up -d
  #
  ############################################################

  mergin-sync:
    image: *mergin-db-sync-image
    profiles: 
      - mergin
    volumes:
      # We do this so we can easily inspect what is being pulled
      # down from mergin, flush the working dir when needed etc
      - mergin_sync_data:/tmp
    env_file: .env
    environment:
      - DB_CONN_INFO=host=db dbname=${MERGIN_DATABASE} user=${POSTGRES_USER} password=${POSTGRES_PASSWORD} sslmode=require
      - DB_SCHEMA_MODIFIED=${DB_SCHEMA_MODIFIED}
      - DB_SCHEMA_BASE=${DB_SCHEMA_BASE}
      - MERGIN_USERNAME=${MERGIN_USER}
      - MERGIN_PASSWORD=${MERGIN_PASSWORD}
      - MERGIN_PROJECT_NAME=${MERGIN_PROJECT_NAME}
      - MERGIN_SYNC_FILE=${MERGIN_SYNC_FILE}
    # Ultimately we want to swap to having the db as the master
    # copy. If you are using the geopackage as the master copy:
    entrypoint: "python3 dbsync_daemon.py --init-from-gpkg"
    # If you are using the database as the master copy:
    #entrypoint: "python3 dbsync_daemon.py --init-from-db"
    networks:
     - os-gis-stack
    restart: unless-stopped
    depends_on:
      - db 

  ##############################################################
  # Will just check out a project and update every interval
  ##############################################################
  mergin-client:
    image: *mergin-client-image
    profiles: 
      - mergin-client
    env_file: .env
    environment:
      - MERGIN_URL=${MERGIN_URL}
      - MERGIN_USER=${MERGIN_USER}
      - MERGIN_PASSWORD=${MERGIN_PASSWORD}
    command: "download"
    command: "download tim1/GloriousProjectOfMagnificence /home/mergin/project"
    #command: "/bin/sh -c 'set -x; mergin.sh download $MERGIN_PROJECT; while :; do sleep 1m & wait $${!}; set -x; cd $MERGIN_PROJECT; mergin pull; cd ..; done' "
    
    volumes:
      # Host mounted volume
      # Mounted in SCP and to QGIS Server for serving QGIS projects
      - qgis_projects:/home/mergin
    networks:
     - os-gis-stack

  ############################################################
  #
  # OSM Sync Services - these are not run in production by
  # default - to run them do:
  #
  # docker-compose --profile=osm up -d
  #
  ############################################################

  imposm:
    image: *imposm-image
    profiles: 
      - osm
    volumes:
      # These are sharable to other containers
      - ./conf/osm_conf:/home/settings
      - osm_import_done:/home/import_done
      - osm_import_queue:/home/import_queue
      - osm_cache:/home/cache
    depends_on:
      - db
    networks:
     - os-gis-stack
    env_file: .env
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASS=${POSTGRES_PASSWORD}
      - POSTGRES_DBNAME=gis
      - POSTGRES_PORT=${POSTGRES_PRIVATE_PORT}
      - POSTGRES_HOST=db
      - SSL_MODE=require
      # seconds between 2 executions of the script if 0, then no
      # update will be done, only the first initial import from the
      # PBF
      - TIME=120
      # folder for settings (with *.json and *.sql)
      - SETTINGS=settings
      # folder for caching
      - CACHE=cache
      # folder for diff which has been imported
      - IMPORT_DONE=import_done
      # folder for diff which hasn't been imported yet
      - IMPORT_QUEUE=import_queue
      # it can be 3857
      - SRID=4326
      # see http://imposm.org/docs/imposm3/latest/tutorial.html#optimize
      - OPTIMIZE=false
      # see http://imposm.org/docs/imposm3/latest/tutorial.html#deploy-production-tables
      - DBSCHEMA_PRODUCTION=osm
      # http://imposm.org/docs/imposm3/latest/tutorial.html#deploy-production-tables
      - DBSCHEMA_IMPORT=osm_import
      # http://imposm.org/docs/imposm3/latest/tutorial.html#deploy-production-tables
      - DBSCHEMA_BACKUP=osm_backup
      # Install some styles if you are using the default mapping.
      # It can be 'yes' or 'no'
      - QGIS_STYLE=yes
      # Use clip in the database
      - CLIP=yes

  osmupdate:
    image: *osm-update-image
    profiles: 
      - osm
    volumes:
      # These are sharable to other containers
      - ./conf/osm_conf:/home/settings
      - osm_import_done:/home/import_done
      - osm_import_queue:/home/import_queue
      - osm_cache:/home/cache
    depends_on:
      - db
    networks:
     - os-gis-stack
    environment:
      # These are all currently the defaults but listed here for
      # your convenience if you want to change them.
      
      # The maximum time range to assemble a cumulated changefile.
      - MAX_DAYS=100
      # osmupdate uses a combination of minutely, hourly and daily
      # changefiles. This value can be minute, hour, day or
      # sporadic.
      - DIFF=sporadic
      # argument to determine the maximum number of parallely
      # processed changefiles.
      - MAX_MERGE=7
      # define level for gzip compression. values between 1 (low
      # compression but fast) and 9 (high compression but slow)
      - COMPRESSION_LEVEL=1
      # change the URL to use a custom URL to fetch regional file
      # updates.
      - BASE_URL=http://planet.openstreetmap.org/replication/
      # folder for diff which hasn't been imported yet
      - IMPORT_QUEUE=import_queue
      # folder for diff which has been imported
      - IMPORT_DONE=import_done
      # seconds between 2 executions of the script
      # if 0, then no update will be done, only the first initial
      # import from the PBF
      - TIME=120

  # This server updates user and date of osm edits in the mirror
  osmenrich:
    image: *osm-enrich-image
    profiles: 
      - osm-enrich
    volumes:
      # These are sharable to other containers
      - ./conf/osm_conf:/home/settings
      - osm_import_done:/home/import_done
      - osm_import_queue:/home/import_queue
      - osm_cache:/home/cache
    depends_on:
      - db
    networks:
     - os-gis-stack
    env_file: .env
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASS=${POSTGRES_PASSWORD}
      - POSTGRES_DBNAME=gis
      - POSTGRES_PORT=${POSTGRES_PRIVATE_PORT}
      - POSTGRES_HOST=db
      - SSL_MODE=require
      # These are all currently the defaults but listed here for
      # your convenience if you want to change them.
      # folder for diff which hasn't been imported yet
      # - IMPORT_QUEUE=import_queue
      # folder for diff which has been imported
      # - IMPORT_DONE=import_done
      # seconds between 2 executions of the script
      # if 0, then no update will be done, only the first initial import from the PBF
      # - TIME=120
      # command: bash -c "while [ ! -f /home/settings/importer.lock ] ; do sleep 1; done && python3 -u /home/enrich.py"

  ############################################################
  #
  #
  # Mergin Server services. See https://github.com/lutraconsulting/mergin
  # 
  #
  ############################################################

  mergin-server:
    image: lutraconsulting/mergin
    profiles:
      - mergin-server
    volumes:
      - mergin-projects:/data  # map data dir to host
    env_file: .env      
    environment:
      - VERSION=${MERGIN_SERVER_VERSION}
      - SWAGGER_UI=0
      - SECRET_KEY=${MERGIN_SERVER_SECRET_KEY}
      - SECURITY_PASSWORD_SALT=fixme
      - LOCAL_PROJECTS=/data
      - MAINTENANCE_FILE=/data/MAINTENANCE
      - USER_SELF_REGISTRATION=1
      - USE_X_ACCEL=${MERGIN_SERVER_USE_X_ACCEL}
      - GEODIFF_LOGGER_LEVEL=${MERGIN_SERVER_GEODIFF_LOGGER_LEVEL}
      - TEMP_DIR=/data/tmp
      - MERGIN_TESTING=${MERGIN_SERVER_MERGIN_TESTING}
      - MAX_CHUNK_SIZE=${MERGIN_SERVER_MAX_CHUNK_SIZE}
      - TEMP_EXPIRATION=${MERGIN_SERVER_TEMP_EXPIRATION}
      - DELETED_PROJECT_EXPIRATION=${MERGIN_SERVER_DELETED_PROJECT_EXPIRATION}
      - CLOSED_ACCOUNT_EXPIRATION=${MERGIN_SERVER_CLOSED_ACCOUNT_EXPIRATION}
      - DEFAULT_STORAGE_SIZE=${MERGIN_SERVER_DEFAULT_STORAGE_SIZE}
      # TODO - create separate user for mergin db so it does not have superuser rights
      - DB_USER=${POSTGRES_USER}
      - DB_PASSWORD=${POSTGRES_PASSWORD}
      - DB_HOST=db
      - DB_PORT=${POSTGRES_PRIVATE_PORT}
      # Check if this is the db name?
      - DB_APPLICATION_NAME=mergin-server
      - MAIL_SUPPRESS_SEND=${MERGIN_SERVER_MAIL_SUPPRESS_SEND}
      - MAIL_SERVER=${MERGIN_SERVER_MAIL_SERVER}
      - MAIL_DEFAULT_SENDER=${MERGIN_SERVER_MAIL_DEFAULT_SENDER}
      - MAIL_USERNAME=${MERGIN_SERVER_MAIL_USERNAME}
      - MERGIN_BASE_URL=${MERGIN_SERVER_MERGIN_BASE_URL}
      - MERGIN_LOGO_URL=${MERGIN_SERVER_MERGIN_LOGO_URL}
      - CONTACT_EMAIL=${MERGIN_SERVER_CONTACT_EMAIL}
      - SLACK_HOOK_URL=${MERGIN_SERVER_SLACK_HOOK_URL}
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    ports:
      - 5000
    depends_on:
      - db
      - redis
    networks:
      - os-gis-stack   
      

  ############################################################
  #
  #
  # Mergin client services. These are all run once containers.
  # 
  # The idea is to checkout the projects that have been shared
  # with the designated user into a directory and then publish
  # those using QGIS Server (or GeoServer if you like.).scp_qgis_projects
  #
  #
  ############################################################
    


  download-project:
    image: *mergin-client-image
    profiles: 
      - mergin-client
    env_file: .env
    environment:
      - MERGIN_URL=${MERGIN_URL}
      - MERGIN_USER=${MERGIN_USER}
      - MERGIN_PASSWORD=${MERGIN_PASSWORD}
    command: "download tim1/GloriousProjectOfMagnificence /home/mergin/project"
      #command: "/bin/sh -c 'set -x; mergin.sh download $MERGIN_PROJECT; while :; do sleep 1m & wait $${!}; set -x; cd $MERGIN_PROJECT; mergin pull; cd ..; done' "
    volumes:
      - qgis_projects:/home/mergin

  pull-projects:
    image: *mergin-client-image
    profiles: 
      - mergin-client
    env_file: .env
    environment:
      - MERGIN_URL=${MERGIN_URL}
      - MERGIN_USER=${MERGIN_USER}
      - MERGIN_PASSWORD=${MERGIN_PASSWORD}
    command: "pull"
    volumes:
      - qgis_projects:/home/mergin

  list-shared-projects:
    image: *mergin-client-image
    profiles: ["mergin-client"]
    env_file: .env
    environment:
      - MERGIN_URL=${MERGIN_URL}
      - MERGIN_USER=${MERGIN_USER}
      - MERGIN_PASSWORD=${MERGIN_PASSWORD}
    command: "list-projects --flag shared"
    volumes:
      - qgis_projects:/home/mergin

  download-shared-projects:
    image: *mergin-client-image
    profiles: ["mergin-client"]
    env_file: .env
    environment:
      - MERGIN_URL=${MERGIN_URL}
      - MERGIN_USER=${MERGIN_USER}
      - MERGIN_PASSWORD=${MERGIN_PASSWORD}
    command: "download-shared"
    volumes:
      - qgis_projects:/home/mergin

  ############################################################
  #
  #
  # ODM Services. These are all run once containers.
  #
  #
  ############################################################
    
  odm:
    # A run once container that will process a batch of images and
    # generate an orthophoto, DSM and DEM
    # see https://github.com/OpenDroneMap/ODM#quickstart
    # docker run -ti --rm -v /home/youruser/datasets:/datasets opendronemap/odm --project-path /datasets project
    # Treat this as a run-once job and run it using either
    # docker-compose --profile=odm run odm
    # or 
    # make odm
    image: *odm-image
    # Only runs when you do docker-compose --profile=odm imposm
    profiles: 
      - odm
    volumes:
      # odm datasets should be arranged with project folders each
      # containing an images folder e.g.
      # datasets/smallholding/images
      - scp_odm_data:/datasets
    restart: never
    entrypoint: "python3 /code/run.py --project-path /datasets --dsm --dtm --orthophoto-resolution 2 smallholding"

  odm-ortho-clip:
    
    # A run once container that will clip processed dsm, dtm,
    # orthophoto images created using the odm service above
    # see https://github.com/geo-data/gdal-docker
    # example usage : 
    # docker run -v $(pwd):/data geodata/gdal gdalinfo test.tif
    #
    # Treat this as a run-once job and run it using either
    # docker-compose --profile=odm run odm-ortho-clip
    # or 
    # make odm
    #
    # I think we can use image: kartoza/postgis:13.0 rather and
    # then we get pg support too
    image: *gdal-image
    # Only runs when you do docker-compose --profile=odm .....
    profiles: 
      - odm
    volumes:
      # odm datasets should be arranged with project folders each
      # containing an images folder e.g.
      # datasets/projectfoo/images
      - scp_odm_data:/datasets
      - odm_cutline:/cutline
    restart: never
    entrypoint: "gdalwarp -overwrite -cutline /cutline/cutline.shp -crop_to_cutline -dstalpha /datasets/smallholding/odm_orthophoto/odm_orthophoto.tif /datasets/orthophoto.tif"

  odm-dsm-clip:
    
    # A run once container that will clip processed dsm, dtm,
    # orthophoto images created using the odm service above
    # see https://github.com/geo-data/gdal-docker
    # example usage : 
    # docker run -v $(pwd):/data geodata/gdal gdalinfo test.tif
    #
    # Treat this as a run-once job and run it using either
    # docker-compose --profile=odm run odm-dsm-clip
    # or 
    # make odm
    #
    # I think we can use image: kartoza/postgis:13.0 rather and
    # then we get pg support too    
    image: *gdal-image
    # Only runs when you do docker-compose --profile=odm .....
    profiles: 
      - odm
    volumes:
      # odm datasets should be arranged with project folders each
      # containing an images folder e.g.
      # datasets/projectfoo/images
      - odm_datasets:/datasets
      - odm_cutline:/cutline
    restart: never
    entrypoint: "gdalwarp -overwrite -cutline /cutline/cutline.shp -crop_to_cutline -dstalpha /datasets/smallholding/odm_dem/dsm.tif /datasets/dsm.tif"

  odm-dtm-clip:
    
    # A run once container that will clip processed dsm, dtm,
    # orthophoto images created using the odm service above
    # see https://github.com/geo-data/gdal-docker
    # example usage : 
    # docker run -v $(pwd):/data geodata/gdal gdalinfo test.tif
    #
    # Treat this as a run-once job and run it using either
    # docker-compose --profile=odm run odm-dem-clip
    # or 
    # make odm
    #
    # I think we can use image: kartoza/postgis:13.0 rather and
    # then we get pg support too    
    image: *gdal-image
    # Only runs when you do docker-compose --profile=odm .....
    profiles: 
      - odm
    volumes:
      # odm datasets should be arranged with project folders each
      # containing an images folder e.g.
      # datasets/projectfoo/images
      - odm_datasets:/datasets
      - odm_cutline:/cutline
    restart: never
    entrypoint: "gdalwarp -overwrite -cutline /cutline/cutline.shp -crop_to_cutline -dstalpha /datasets/smallholding/odm_dem/dtm.tif /datasets/dtm.tif"

  osm-to-mbtiles:
    # A run once container that export the docker-osm schema to an
    # mbtiles store
    # Treat this as a run-once job and run it using either
    # docker-compose --profile osm run osm-to-mbtiles
    # or 
    # make osm-to-mbtiles
    #
    # Broken for now, see Makefile osm-to-mbtiles target for
    # details
    image: *postgres-image
    profiles: 
      - osm-tiles
    networks:
      - os-gis-stack
    volumes:
      # This is a bit naughty as the mergindb sync checkout should
      # be treated read only, but trying anyway to see if it works
      # because if it does it could be a nice way to provision an 
      # updated tileset whenever you run this
      - mergin_sync_data:/data
    restart: never
    entrypoint: "ogr2ogr -f MBTILES /data/osm.mbtiles PG:\"dbname='gis' host='db' port='5432' user='docker' password='docker' SCHEMAS=osm\" -dsco \"MAXZOOM=10\" -dsco \"BOUNDS=-7.389126,39.410085,-7.381439,39.415144\""



networks:
  os-gis-stack:
